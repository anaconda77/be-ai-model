import sys, os
import numpy as np
from datetime import datetime, timedelta
import pandas as pd
from supabase import create_client, Client
import finnhub
from dotenv import load_dotenv
from tensorflow.keras.models import load_model
import pickle
from config import STOCK_LIST

base_dir = os.path.dirname(__file__)
parent_path = os.path.join(base_dir, '..')
sys.path.append(parent_path)

from source.input_processing import get_csv_data, merge_data
from source.sentiment_model import analyze_sentiment_with_progress, add_integer_column, sums_sentiment_score_for_7_days, update_sentiment_score_in_db
from source.lstm_model import get_scale_data, get_scale_data_with_fit, create_sequences_for_train, compile_model, train_model, predict_prices, create_sequences_for_prod
from source.output_processing import compare_prices_with_graph
from source.market_capitalization import get_capitalization

SEQUENCE_LENGTH = 7
SENTIMENT_WINDOW_DAYS = 7
FETCH_DAYS = 13

load_dotenv()

SUPABASE_URL = os.environ.get('SUPABASE_URL')
SUPABASE_API_KEY = os.environ.get('SUPABASE_API_KEY')
FINNHUB_API_KEY = os.environ.get('FINNHUB_API_KEY')

supabase: Client = create_client(SUPABASE_URL, SUPABASE_API_KEY)
finnhub_client = finnhub.Client(api_key=FINNHUB_API_KEY)

def get_price_data_from_db(stock_id):
  prices_latest_date_response = supabase.table('stock_prices').select('price_date') \
          .eq('stock_id', stock_id) \
          .order('price_date', desc=True) \
          .limit(1) \
          .single() \
          .execute()

  if not prices_latest_date_response.data:
      print(f"ğŸš¨ '{stock_id}'ì— ëŒ€í•œ ìµœê·¼ì˜ ì£¼ê°€ ë°ì´í„°ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")

  prices_latest_date = prices_latest_date_response.data['price_date']

  prices_response = supabase.table('stock_prices').select('*') \
          .eq('stock_id', stock_id) \
          .lte('price_date', prices_latest_date) \
          .order('price_date', desc=True) \
          .limit(FETCH_DAYS) \
          .execute()

  return prices_response.data

def get_news_data_from_db(start_date, end_date, stock_id):

  news_response = supabase.table('news').select('*').eq('stock_id', stock_id) \
  .gte('created_date', start_date.strftime('%Y-%m-%d')) \
  .lte('created_date', end_date.strftime('%Y-%m-%d')) \
  .execute()

  if not news_response.data:
      print(f"ğŸš¨ '{stock_id}'ì— ëŒ€í•œ ìµœê·¼ì˜ ë‰´ìŠ¤ ë°ì´í„°ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")

  return news_response.data

def get_existing_model(stock_code):
    """ëª¨ë¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤."""
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    load_path = os.path.join(base_dir, 'models', f'{stock_code}_finn_model.keras')
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
    return load_model(load_path)

def get_existing_scaler(stock_code):
    """ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. íŒŒì¼ì´ ì—†ìœ¼ë©´ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤."""
    base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
    load_path = os.path.join(base_dir, 'models', f'{stock_code}_finn_scaler.pkl')
    if not os.path.exists(load_path):
        raise FileNotFoundError(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {load_path}")
    with open(load_path, 'rb') as f:
        scaler = pickle.load(f)
    return scaler

def get_change_rate(prev_price, today_price):
    change_rate = ((today_price - prev_price) / prev_price) * 100
    return change_rate.round(2)

def get_closely_prev_close_price(df):
    # 2. 'close_price'ê°€ NaN(ë¹„ì–´ìˆì§€ ì•Šì€)ì´ ì•„ë‹Œ í–‰ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.
    valid_data_df = df.dropna(subset=['close_price'])

    # 3. ì¸ë±ìŠ¤(date)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬í•˜ì—¬ ê°€ì¥ ìµœì‹  ë°ì´í„°ê°€ ë§¨ ìœ„ë¡œ ì˜¤ê²Œ í•©ë‹ˆë‹¤.
    sorted_df = valid_data_df.sort_index(ascending=False)

    latest_valid_row = sorted_df.iloc[0]
    
    # ì¸ë±ìŠ¤ê°€ ë‚ ì§œì´ë¯€ë¡œ, .name ì†ì„±ìœ¼ë¡œ ë‚ ì§œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    latest_date = latest_valid_row.name.strftime('%Y-%m-%d')
    latest_close_price = latest_valid_row['close_price']

    
    return latest_close_price
# Predictions rowë¥¼ ë§Œë“¤ê³ , dbì— ì €ì¥(ì‹œê°€ì´ì•¡ ì •ë³´ë„ í˜¸ì¶œí•˜ì—¬ ì €ì¥)
def save_predictions_in_db(stock_id, stock_code, company_name, prediction_price, prediction_date, change_rate, capitalization):
    try :
        response = supabase.table('predictions') \
        .upsert({"stock_id" : stock_id, "prediction_date": prediction_date, "stock_code" : stock_code,
                "company_name" : company_name, "prediction_price" : prediction_price, "change_rate" : change_rate,
                "capitalization" : capitalization}) \
        .execute()
        
        if hasattr(response, 'error') and response.error is not None:
                print(f"ğŸš¨ DB ì—…ë°ì´íŠ¸ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {response.error}")
        else:
            print("âœ… DB ì—…ë°ì´íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ğŸš¨ DB ì—…ë°ì´íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

def run_prediction_for_stock(stock_code: str):
    """ë‹¨ì¼ ì£¼ì‹ ì½”ë“œì— ëŒ€í•œ ì „ì²´ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("\n" + "="*50)
    print(f"ğŸš€ {stock_code} ì˜ˆì¸¡ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    print("="*50)

    # 1. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    model = get_existing_model(stock_code)
    scaler = get_existing_scaler(stock_code)

    # 2. DBì—ì„œ ë°ì´í„° ì¡°íšŒ
    stock_response = supabase.table('stocks').select('id,stock_code,company_name').eq('stock_code', stock_code).single().execute()
    if not stock_response.data:
        raise ValueError(f"'{stock_code}' ì •ë³´ë¥¼ 'stocks' í…Œì´ë¸”ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    stock_id = stock_response.data['id']
    company_name = stock_response.data['company_name']

    prices_data = get_price_data_from_db(stock_id)
    if not prices_data:
        raise ValueError(f"'{stock_code}'ì˜ ì£¼ê°€ ë°ì´í„°ê°€ DBì— ì—†ìŠµë‹ˆë‹¤.")
    stock_prices_df = pd.DataFrame(prices_data)

    # 3. ë°ì´í„° ê²€ì¦ (ê¸¸ì´ í™•ì¸)
    if len(stock_prices_df) < FETCH_DAYS:
        raise ValueError(f"ì£¼ê°€ ë°ì´í„° ë¶€ì¡±: ì˜ˆì¸¡ì— í•„ìš”í•œ {FETCH_DAYS}ì¼ì¹˜ ë°ì´í„° ì¤‘ {len(stock_prices_df)}ì¼ì¹˜ë§Œ ì¡°íšŒë¨.")
    
    # ... (ì´í›„ ë°ì´í„° ì²˜ë¦¬ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
    stock_prices_df = stock_prices_df.rename(columns={'price_date':'date', 'id' : 'stock_price_id'})
    start_date = pd.to_datetime(stock_prices_df['date']).min()
    end_date = pd.to_datetime(stock_prices_df['date']).max()

    news_response = get_news_data_from_db(start_date, end_date, stock_id)
    news_df = pd.DataFrame(news_response)
    news_df = news_df.rename(columns={'created_date':'date', 'id' : 'news_id'})
    # ê°ì •í‰ê°€ ìˆ˜í–‰ í›„, sentiment_scoreë¥¼ db news í…Œì´ë¸”ì— ìƒˆë¡­ê²Œ ì—…ë°ì´íŠ¸í•œë‹¤.
    news_df = analyze_sentiment_with_progress(news_df)

    merged_df = merge_data(news_df, stock_prices_df)
    merged_df['sentiment_influence'] = 0.0
    merged_df = add_integer_column(merged_df)

    sums_sentiment_score_for_7_days(merged_df)
    update_sentiment_score_in_db(supabase, merged_df)
    
    features = ['sentiment_influence', 'open', 'high', 'low', 'adjClose', 'volume']
    target = 'close'
    all_cols = features + [target]

    dropped_merged_df = merged_df.rename(columns={'open_price':'open', 'high_price' : 'high', 'low_price' : 'low', 'close_price' : 'close', 'adj_close_price' : 'adjClose'})
    dropped_merged_df = dropped_merged_df[ features + [target] ].dropna()
    
    # 4. ìµœì¢… ì…ë ¥ ë°ì´í„° ê²€ì¦
    # dropped_merged_df ìƒì„±...
    if len(dropped_merged_df) < SEQUENCE_LENGTH:
        raise ValueError(f"ìµœì¢… ë°ì´í„° ë¶€ì¡±: ëª¨ë¸ ì…ë ¥ì— í•„ìš”í•œ {SEQUENCE_LENGTH}ì¼ì¹˜ ë°ì´í„° ìƒì„± ì‹¤íŒ¨ ({len(dropped_merged_df)}ì¼ì¹˜ë§Œ ìƒì„±ë¨).")
        
    # 5. ìŠ¤ì¼€ì¼ë§ ë° ì˜ˆì¸¡
    scaled = get_scale_data(scaler, dropped_merged_df)
    X = create_sequences_for_prod(scaled)
    
    y_pred_scaled = predict_prices(model, X)
    all_cols = ['sentiment_influence', 'open', 'high', 'low', 'adjClose', 'volume', 'close']
    features = all_cols[:-1] # 'close'ë¥¼ ì œì™¸í•œ ëª¨ë“  ì»¬ëŸ¼
    target = 'close'
    target_col_index = all_cols.index(target)

    num_features = len(features)
    dummy_array = np.zeros((len(y_pred_scaled), len(all_cols)))

    # 'close' ìœ„ì¹˜(6ë²ˆ ì¸ë±ìŠ¤)ì— ì˜ˆì¸¡ëœ ê°’ì„ ì‚½ì…
    dummy_array[:, target_col_index] = y_pred_scaled.ravel()
    # Scalerë¥¼ ì´ìš©í•´ ì „ì²´ ë°°ì—´ì„ ì—­ë³€í™˜í•˜ê³ , 'close' ì»¬ëŸ¼ë§Œ ì¶”ì¶œ
    y_pred_actual = scaler.inverse_transform(dummy_array)[:, target_col_index]

    next_day_predicted_close = y_pred_actual[-1].round(4)
    closely_prev_price = get_closely_prev_close_price(merged_df)
    change_rate = get_change_rate(closely_prev_price, next_day_predicted_close)

    print(f"ì˜ˆì¸¡ëœ ì‹¤ì œ ì¢…ê°€: ${next_day_predicted_close:.4f}")
    capitalization = get_capitalization(finnhub_client, stock_code)
    today_date = datetime.now().strftime("%Y-%m-%d")
    save_predictions_in_db(stock_id, stock_code, company_name, next_day_predicted_close, today_date, change_rate, capitalization)
    print(f"âœ… {stock_code} ì˜ˆì¸¡ ë° ì €ì¥ ì™„ë£Œ.")


def main():
    """STOCK_LISTì— ìˆëŠ” ëª¨ë“  ì£¼ì‹ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("===== ì „ì²´ ì£¼ê°€ ì˜ˆì¸¡ ì‘ì—…ì„ ì‹œì‘í•©ë‹ˆë‹¤ =====")
    
    # config.py ì— ì •ì˜ëœ ì£¼ì‹ ë¦¬ìŠ¤íŠ¸
    # STOCK_LIST = ['AAPL', 'TSLA', 'GOOGL', 'NON_EXISTENT_STOCK'] 
    
    for stock_code in STOCK_LIST:
        try:
            # ê° ì£¼ì‹ì— ëŒ€í•œ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
            run_prediction_for_stock(stock_code)
        
        except FileNotFoundError as e:
            # ëª¨ë¸ì´ë‚˜ ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°
            print(f"ğŸš¨ [ì—ëŸ¬] {stock_code}: ì²˜ë¦¬ ê±´ë„ˆëœ€ (ì›ì¸: {e})")
        
        except ValueError as e:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            print(f"ğŸš¨ [ì—ëŸ¬] {stock_code}: ì²˜ë¦¬ ê±´ë„ˆëœ€ (ì›ì¸: {e})")
        
        except Exception as e:
            # ê·¸ ì™¸ ì˜ˆìƒì¹˜ ëª»í•œ ëª¨ë“  ì—ëŸ¬
            import traceback
            print(f"ğŸš¨ [ì‹¬ê°] {stock_code}: ì²˜ë¦¬ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬ ë°œìƒ. ë‹¤ìŒ ì¢…ëª©ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            # ìƒì„¸í•œ ì—ëŸ¬ ë¡œê·¸ë¥¼ ë³´ê³  ì‹¶ì„ ë•Œ ì•„ë˜ ì£¼ì„ í•´ì œ
            # traceback.print_exc()

    print("\n===== ëª¨ë“  ì£¼ê°€ ì˜ˆì¸¡ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤ =====")


if __name__ == '__main__':
    main()